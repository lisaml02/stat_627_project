---
title: "model_tuning"
output: html_document
date: "2024-06-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading in data and splitting}
library(tidyverse)
library(ggplot2)
library(car)
library(MASS)
library(caret)
library(dplyr)

inst_clean <- read_csv("./inst_clean.csv") %>% 
  dplyr::select(-TRUST)

set.seed(12345)  
training_pct <- 0.8
Z <- sample(nrow(inst_clean), floor(training_pct*nrow(inst_clean)))
inst.training <- inst_clean[Z, ]
inst.testing <- inst_clean[-Z, ]
c(nrow(inst_clean), nrow(inst.training), nrow(inst.testing))
```

# Logistic Model

## How it Was Fit

Starting with recoding the variable BKCLASS to be binary.

```{r recoding BKCLASS}
commercial_bank_categories <- c("N", "NM", "SM", "NC")

inst.training$CommercialBank <- ifelse(inst.training$BKCLASS %in% commercial_bank_categories, 1, 0)
print(inst.training)
```

```{r recoding BKCLASS for test data}
inst.testing$CommercialBank <- ifelse(inst.testing$BKCLASS %in% commercial_bank_categories, 1, 0)
print(inst.testing)
```

Now we fit the Model

```{r fitting the logistic model}
# predicting whether or not the bank is a commericial bank or not

logit_inst <- glm(CommercialBank ~ ASSET + DEP + DEPDOM + EQ + NETINC + ROA + ROAPTX + ROAPTXQ + ROAQ, data = inst.training, family = "binomial")
summary(logit_inst)
```

Residual deviance: 17622

## Tuning

```{r standardizing features}

# Exclude non-numeric columns and response variable from training set
train_x <- inst.training[, sapply(inst.training, is.numeric) & names(inst.training) != "CommercialBank"]
train_y <- inst.training$CommercialBank

# Exclude non-numeric columns and response variable from testing set
test_x <- inst.testing[, sapply(inst.testing, is.numeric) & names(inst.testing) != "CommercialBank"]
test_y <- inst.testing$CommercialBank

# Standardize features
train_x_scaled <- scale(train_x)
test_x_scaled <- scale(test_x, center = attr(train_x_scaled, "scaled:center"), scale = attr(train_x_scaled, "scaled:scale"))

```

```{r k-fold CV}
# Fit LASSO model using cv.glmnet
library(glmnet)

# Example data preparation (replace with your actual data)
x_train <- as.matrix(train_x_scaled)  # Assuming train_x_scaled is standardized numeric features
y_train <- as.factor(train_y)  # Convert train_y to factor for binomial family

# Fit LASSO model using cross-validation to select lambda
cv_model <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 1, nfolds = 5)
best_lambda <- cv_model$lambda.min

# Fit final LASSO model using the selected lambda
lasso_model <- glmnet(x_train, y_train, family = "binomial", alpha = 1, lambda = best_lambda)

# Extract coefficients from LASSO model
lasso_coefficients <- coef(lasso_model, s = best_lambda)

# Convert coefficients to a regular matrix
lasso_coefficients_matrix <- as.matrix(lasso_coefficients)

# Extract names of non-zero coefficients (selected features)
selected_features <- rownames(lasso_coefficients_matrix)[lasso_coefficients_matrix != 0]
print(selected_features)

```

Here is the model:

```{r fitting selected logit model}
final_logit <- glm(CommercialBank ~ ASSET + DEPDOM + MUTUAL + NETINC + ROA, data = inst.training, family = "binomial")
summary(final_logit)
```

Residual deviance: 13488

## Assessing Model Performance

```{r assessing model performance}
# Predicted probabilities on training data
train_pred_probs <- predict(final_logit, type = "response")

# Predicted classes (binary) based on a threshold (typically 0.5)
train_pred <- ifelse(train_pred_probs > 0.5, 1, 0)

# Compute training error rate
train_error_rate <- mean(train_pred != inst.training$CommercialBank)
cat("Training Error Rate:", train_error_rate, "\n")

# Compute residual deviance
residual_deviance <- deviance(final_logit)
cat("Residual Deviance:", residual_deviance, "\n")

# Confusion Matrix
train_conf_matrix <- table(Predicted = train_pred, Actual = inst.training$CommercialBank)
cat("Confusion Matrix:\n")
print(train_conf_matrix)

# ROC Curve and AUC
library(pROC)
roc_obj <- roc(inst.training$CommercialBank, train_pred_probs)
plot(roc_obj, main = "ROC Curve - Training Data")
auc <- auc(roc_obj)
cat("Training AUC:", auc, "\n")

```

# Linear Model with Boostrap

## How the Model Was Fit

## Tuning

## Assessing Model Accuracy
